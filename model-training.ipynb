{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Nombre: Alberto José Mendoza Peñaloza\n",
        "## Prueba Ingeniero de IA Mercately"
      ],
      "metadata": {
        "id": "nMwDTgPbSYAW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMKaQ7qrSSgM",
        "outputId": "d63fdaf4-7444-4ccb-eb71-1e32650b3b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Importar librerías"
      ],
      "metadata": {
        "id": "nSIrZHbihXT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "# Libreria de NLP\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Librerias de manejo de datos\n",
        "import os\n",
        "import re\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata\n",
        "\n",
        "# Entrenamiento y Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8JD5u-3n-vU",
        "outputId": "f4f470b8-3c22-4f74-e41a-e3caa311eae4"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Cargar datos"
      ],
      "metadata": {
        "id": "mwH9yzWVnW0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/TESTS/Mercately/data/\""
      ],
      "metadata": {
        "id": "T_uuZXJ-pF9d"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_txt_file(path):\n",
        "  textfile = open(path, \"r\")\n",
        "  content = textfile.read().split('\\n')\n",
        "  textfile.close()\n",
        "  filtered_list = list(filter(lambda s: ':' in s, content))\n",
        "  chat = \"\".join(filtered_list)\n",
        "  return chat"
      ],
      "metadata": {
        "id": "ebXMXFiT65Nt"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'class':[],\n",
        "        'text':[]}\n",
        "\n",
        "class0_path = data_path+\"class0\"\n",
        "for f in os.listdir(class0_path):\n",
        "  path = class0_path+'/'+f\n",
        "  data['text'].append(read_txt_file(path))\n",
        "  data['class'].append(0)\n",
        "\n",
        "\n",
        "class1_path = data_path+\"class1\"\n",
        "for f in os.listdir(class1_path):\n",
        "  path = class1_path+'/'+f\n",
        "  data['text'].append(read_txt_file(path))\n",
        "  data['class'].append(1)"
      ],
      "metadata": {
        "id": "7AiLQHORuTpP"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "SRkkA4tovy14"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "D_iXRhEsxTMj",
        "outputId": "f067bb28-74c4-43a7-aedb-96c6945a0aae"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    class                                               text\n",
              "4       0  Vendedor: ¡Buenos días! Bienvenido a nuestra t...\n",
              "29      1  Vendedor: Buenos días, ¿en qué puedo ayudarlo ...\n",
              "16      0  Vendedor: ¡Hola! ¿En qué puedo ayudarte hoy?Co...\n",
              "6       0  Vendedor: Buenas tardes, ¿en qué puedo ayudarl...\n",
              "24      1  Vendedor: ¡Buenos días! Bienvenido a nuestra t..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6bc4686-4566-497a-a4f4-d57ff63bca7e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Vendedor: ¡Buenos días! Bienvenido a nuestra t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>Vendedor: Buenos días, ¿en qué puedo ayudarlo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>Vendedor: ¡Hola! ¿En qué puedo ayudarte hoy?Co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>Vendedor: Buenas tardes, ¿en qué puedo ayudarl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>Vendedor: ¡Buenos días! Bienvenido a nuestra t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6bc4686-4566-497a-a4f4-d57ff63bca7e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6bc4686-4566-497a-a4f4-d57ff63bca7e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6bc4686-4566-497a-a4f4-d57ff63bca7e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f0d497ec-f061-4c10-a873-fcd2b04b4872\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0d497ec-f061-4c10-a873-fcd2b04b4872')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f0d497ec-f061-4c10-a873-fcd2b04b4872 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Vendedor: Buenos d\\u00edas, \\u00bfen qu\\u00e9 puedo ayudarlo hoy?Comprador: \\u00a1Hola! Estoy buscando un bolso elegante para regalarle a mi esposa por su cumplea\\u00f1os.Vendedor: Tenemos una amplia variedad de bolsos, \\u00bftiene alg\\u00fan estilo en mente?Comprador: Algo que sea moderno pero cl\\u00e1sico, \\u00bftiene algo as\\u00ed?Vendedor: Claro, tenemos este modelo de cuero que creo que le encantar\\u00e1. \\u00bfQuiere verlo?Comprador: S\\u00ed, por favor. \\u00bfCu\\u00e1l es el precio?Vendedor: Este bolso est\\u00e1 a $200, pero puedo hacerle un descuento del 10% si decide llevarlo hoy.Comprador: Eso suena bien. \\u00bfTiene alg\\u00fan color diferente?Vendedor: S\\u00ed, tambi\\u00e9n est\\u00e1 disponible en negro y marr\\u00f3n.Comprador: Perfecto, creo que el negro ser\\u00e1 el mejor. Lo llevar\\u00e9.Vendedor: Excelente elecci\\u00f3n. \\u00bfDesea agregar alg\\u00fan accesorio adicional?Comprador: \\u00bfTiene alguna billetera que haga juego con el bolso?Vendedor: S\\u00ed, tenemos una billetera a juego que complementar\\u00eda perfectamente el bolso. \\u00bfLe interesar\\u00eda?Comprador: S\\u00ed, por favor. \\u00bfCu\\u00e1nto es por el bolso y la billetera juntos?Vendedor: Con el descuento, el total ser\\u00eda $340.Comprador: De acuerdo, me los llevo. \\u00bfAceptan tarjeta de cr\\u00e9dito?Vendedor: S\\u00ed, aceptamos todas las principales tarjetas de cr\\u00e9dito. Por favor, siga a la caja.Comprador: Perfecto, vamos.Vendedor: Aqu\\u00ed tiene su bolso y su billetera. \\u00bfLe gustar\\u00eda que le envolvamos el regalo?Comprador: S\\u00ed, por favor. Y \\u00bftienen alguna tarjeta de felicitaci\\u00f3n?Vendedor: S\\u00ed, aqu\\u00ed hay algunas opciones para elegir.Comprador: Tomar\\u00e9 esta con el dise\\u00f1o de flores. \\u00bfPueden escribir un mensaje personalizado?Vendedor: Por supuesto, \\u00bfqu\\u00e9 le gustar\\u00eda que diga?Comprador: \\\"Para mi amada esposa en su d\\u00eda especial. Con todo mi amor, [su nombre].\\\"Vendedor: Entendido, lo escribir\\u00e9 en la tarjeta. \\u00bfHay algo m\\u00e1s en lo que pueda ayudarlo?Comprador: No, eso es todo por hoy. Muchas gracias por su ayuda.Vendedor: \\u00a1Fue un placer! Que tenga un d\\u00eda maravilloso y espero que su esposa disfrute mucho su regalo.Comprador: Gracias, igualmente. \\u00a1Hasta luego!\",\n          \"Vendedor: \\u00a1Buenos d\\u00edas! Bienvenido a nuestra tienda de vajillas. \\u00bfEn qu\\u00e9 puedo ayudarte hoy?Comprador: Hola, estoy buscando un nuevo juego de vajilla para mi comedor.Vendedor: Excelente, tenemos una amplia variedad. \\u00bfTienes algo espec\\u00edfico en mente?Comprador: Me gustar\\u00eda algo elegante y duradero, pero no quiero gastar demasiado.Vendedor: Entiendo. Tenemos este set de porcelana que es muy elegante y a un precio razonable.Comprador: Mmm, se ve bien, pero me preocupa que la porcelana sea demasiado fr\\u00e1gil. \\u00bfTienes algo m\\u00e1s resistente?Vendedor: Claro, tambi\\u00e9n tenemos vajillas de cer\\u00e1mica y melamina. La cer\\u00e1mica es m\\u00e1s resistente y la melamina es pr\\u00e1cticamente irrompible.Comprador: La melamina no me convence, parece m\\u00e1s para uso casual. \\u00bfPuedes mostrarme la cer\\u00e1mica?Vendedor: Por supuesto. Este set de cer\\u00e1mica tiene un dise\\u00f1o moderno y es muy resistente. \\u00bfQu\\u00e9 te parece?Comprador: Est\\u00e1 bien, pero el dise\\u00f1o no me termina de convencer. \\u00bfTienes algo m\\u00e1s cl\\u00e1sico?Vendedor: S\\u00ed, tenemos este otro set con un dise\\u00f1o m\\u00e1s tradicional y es igual de resistente.Comprador: Este es m\\u00e1s de mi gusto, pero el precio est\\u00e1 un poco por encima de mi presupuesto.Vendedor: Entiendo, \\u00bfte gustar\\u00eda ver algunas opciones de descuento o tal vez considerar un set m\\u00e1s peque\\u00f1o?Comprador: Preferir\\u00eda un set completo, pero a un precio m\\u00e1s accesible. \\u00bfHay alguna oferta especial?Vendedor: Actualmente tenemos un descuento del 10% en este set si te inscribes en nuestro programa de fidelidad, que es gratuito.Comprador: Eso suena bien. \\u00bfPodr\\u00edas decirme m\\u00e1s sobre el programa de fidelidad?Vendedor: Claro, es muy sencillo. Solo necesitas llenar un formulario con tus datos b\\u00e1sicos y obtienes descuentos especiales, puntos por cada compra que puedes canjear por productos y acceso a promociones exclusivas.Comprador: Perfecto, eso me gusta. Creo que me inscribir\\u00e9.Vendedor: Excelente decisi\\u00f3n. Aqu\\u00ed tienes el formulario. Mientras lo llenas, te voy preparando el set de vajilla.Comprador: Listo, aqu\\u00ed tienes el formulario completo.Vendedor: Gracias. Aqu\\u00ed est\\u00e1 tu set de vajilla y tu tarjeta de fidelidad. Con el descuento aplicado, el total es de 135 d\\u00f3lares.Comprador: Genial, eso entra en mi presupuesto. Aqu\\u00ed tienes mi tarjeta para el pago.Vendedor: Pago realizado con \\u00e9xito. Gracias por tu compra y por inscribirte en nuestro programa de fidelidad. \\u00bfTe gustar\\u00eda que te enviemos la vajilla a tu domicilio?Comprador: S\\u00ed, por favor. Eso ser\\u00eda muy conveniente.Vendedor: Perfecto, anotaremos tu direcci\\u00f3n y te enviaremos la vajilla sin costo adicional. Llegar\\u00e1 en los pr\\u00f3ximos 3 d\\u00edas h\\u00e1biles.Comprador: Excelente, muchas gracias por toda tu ayuda.Vendedor: Ha sido un placer. \\u00a1Que disfrutes tu nueva vajilla! Si necesitas algo m\\u00e1s, no dudes en visitarnos.Comprador: Claro, lo har\\u00e9. \\u00a1Hasta luego!Vendedor: \\u00a1Hasta luego y que tengas un buen d\\u00eda!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Preparación de datos"
      ],
      "metadata": {
        "id": "iwxXtjvanjBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Train-Test Split"
      ],
      "metadata": {
        "id": "U8v-2mRf8d3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['class'],axis=1),data['class'], test_size=0.2, random_state=24)"
      ],
      "metadata": {
        "id": "dkVddUlN8cyH"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Limpieza de datos"
      ],
      "metadata": {
        "id": "gvmpGM04YZxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quitar_tildes(texto):\n",
        "    # Normalizar el texto en forma NFD (Normalization Form D)\n",
        "    texto_normalizado = unicodedata.normalize('NFD', texto)\n",
        "    # Filtrar los caracteres que no son marcas diacríticas\n",
        "    texto_sin_tildes = ''.join(c for c in texto_normalizado if unicodedata.category(c) != 'Mn')\n",
        "    # Devolver el texto sin tildes\n",
        "    return texto_sin_tildes"
      ],
      "metadata": {
        "id": "5I6_FYlpZqMk"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning\n",
        "text = X_train['text'].iloc[0]\n",
        "# getting all the text in lower case\n",
        "text = text.lower()\n",
        "# get accent marks off\n",
        "text = quitar_tildes(text)\n",
        "# Filter punctuation marks and exlude numbers\n",
        "text = re.sub(r'[^a-z\\s]', '', text)"
      ],
      "metadata": {
        "id": "t0mlpR0JYdrR"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Tokenization\n",
        "\n",
        "\n",
        "Get unique words"
      ],
      "metadata": {
        "id": "NAgtezFvLWyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tonekized_text = word_tokenize(text)"
      ],
      "metadata": {
        "id": "NvcsSjC7LDlK"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Stop Words"
      ],
      "metadata": {
        "id": "EpgEiLdgVkNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"spanish\"))\n",
        "words = [word for word in tonekized_text if word not in stop_words]"
      ],
      "metadata": {
        "id": "kxrol4x9SjlZ"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Lematización"
      ],
      "metadata": {
        "id": "cIkkalW8XnaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [lemmatizer.lemmatize(word) for word in words]"
      ],
      "metadata": {
        "id": "-j0BZoSbSjqJ"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Stemming"
      ],
      "metadata": {
        "id": "B4B-T_BpbD5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]"
      ],
      "metadata": {
        "id": "bCqxOeCwbCin"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7 Vectorization\n",
        "\n",
        "use count vectorizer to convert categorical features in numerical"
      ],
      "metadata": {
        "id": "apHhiOm7gdGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(words)"
      ],
      "metadata": {
        "id": "i3LzWMNjgrF8"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.8 Pipeline de Preparación de datos\n",
        "\n",
        "- Haremos un pipeline con stemming y otro pipeline con lemmatizing."
      ],
      "metadata": {
        "id": "XNeTcb_TfZSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "    def quitar_tildes(self,texto):\n",
        "      # Normalizar el texto en forma NFD (Normalization Form D)\n",
        "      texto_normalizado = unicodedata.normalize('NFD', texto)\n",
        "      # Filtrar los caracteres que no son marcas diacríticas\n",
        "      texto_sin_tildes = ''.join(c for c in texto_normalizado if unicodedata.category(c) != 'Mn')\n",
        "      # Devolver el texto sin tildes\n",
        "      return texto_sin_tildes\n",
        "\n",
        "    def manage_stop_words(self,tonekized_text):\n",
        "      stop_words = set(stopwords.words(\"spanish\"))\n",
        "      words = [word for word in tonekized_text if word not in stop_words]\n",
        "      return words\n",
        "\n",
        "    def lemmatization(self,tonekized_text):\n",
        "      lemmatizer = WordNetLemmatizer()\n",
        "      words = [lemmatizer.lemmatize(word) for word in tonekized_text]\n",
        "      return words\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "      X_copy = X.copy()\n",
        "\n",
        "      # Data Cleaning\n",
        "      X_copy['text'] = X_copy['text'].str.lower()\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : self.quitar_tildes(x))\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : re.sub(r'[^a-z\\s]', '', x))\n",
        "      #Tokenization\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : word_tokenize(x))\n",
        "      #stop words\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : self.manage_stop_words(x))\n",
        "      #lemmatization\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : self.lemmatization(x))\n",
        "\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : \" \".join(x))\n",
        "\n",
        "      vectorizer = CountVectorizer()\n",
        "      X = vectorizer.fit_transform(X_copy['text'])\n",
        "      vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "      return vectorized_df\n",
        "\n",
        "pipe_preparacion_lemm = Pipeline(steps=[\n",
        "    ('custom_proccesing', CustomTransformer()),\n",
        "    ('clf', SVC()),\n",
        "])"
      ],
      "metadata": {
        "id": "nqGBtpsffcgt"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "    def quitar_tildes(self,texto):\n",
        "      # Normalizar el texto en forma NFD (Normalization Form D)\n",
        "      texto_normalizado = unicodedata.normalize('NFD', texto)\n",
        "      # Filtrar los caracteres que no son marcas diacríticas\n",
        "      texto_sin_tildes = ''.join(c for c in texto_normalizado if unicodedata.category(c) != 'Mn')\n",
        "      # Devolver el texto sin tildes\n",
        "      return texto_sin_tildes\n",
        "\n",
        "    def manage_stop_words(self,tonekized_text):\n",
        "      stop_words = set(stopwords.words(\"spanish\"))\n",
        "      words = [word for word in tonekized_text if word not in stop_words]\n",
        "      return words\n",
        "\n",
        "    def stemming(self,tonekized_text):\n",
        "      stemmer = PorterStemmer()\n",
        "      stemmed_words = [stemmer.stem(word) for word in tonekized_text]\n",
        "      return words\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "      X_copy = X.copy()\n",
        "\n",
        "      # Data Cleaning\n",
        "      X_copy['text'] = X_copy['text'].str.lower()\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : self.quitar_tildes(x))\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : re.sub(r'[^a-z\\s]', '', x))\n",
        "      #Tokenization\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : word_tokenize(x))\n",
        "      #stop words\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : self.manage_stop_words(x))\n",
        "      #lemmatization\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : self.stemming(x))\n",
        "\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : \" \".join(x))\n",
        "\n",
        "      vectorizer = CountVectorizer()\n",
        "      X = vectorizer.fit_transform(X_copy['text'])\n",
        "      vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "      return vectorized_df\n",
        "\n",
        "\n",
        "pipe_preparacion_stemming = Pipeline(steps=[\n",
        "    ('custom_proccesing', CustomTransformer()),\n",
        "    ('clf', SVC()),\n",
        "])"
      ],
      "metadata": {
        "id": "HJBP43Ansx-n"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Entrenamiento de Modelo"
      ],
      "metadata": {
        "id": "btYcdNFnn4yZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Gridsearch with stemming"
      ],
      "metadata": {
        "id": "8ycbXQeQuGhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for grid search for each model\n",
        "parameters = [\n",
        "    {\n",
        "        'clf': [SVC()],\n",
        "        'clf__kernel': ['linear', 'rbf'],\n",
        "        'clf__C': [1, 10, 100],\n",
        "    },\n",
        "    {\n",
        "        'clf': [RandomForestClassifier()],\n",
        "        'clf__n_estimators': [50, 100, 200,100, 1000],\n",
        "        'clf__max_depth': [None, 10, 20],\n",
        "    },\n",
        "    {\n",
        "        'clf': [LogisticRegression()],\n",
        "        'clf__C': [0.1, 1, 10],\n",
        "        'clf__penalty': ['l1', 'l2'],\n",
        "    },\n",
        "    {\n",
        "        'clf': [MultinomialNB()],\n",
        "        'clf__alpha': [0.01, 0.1, 1.0],\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "vVxWeCXStSg5"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search with scoring parameter\n",
        "grid_search_stem = GridSearchCV(pipe_preparacion_stemming, parameters, scoring='accuracy', verbose=0)"
      ],
      "metadata": {
        "id": "CfEHzma6tSts"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    # Fit the grid search\n",
        "    grid_search_stem.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDOncQt0u8UI",
        "outputId": "a4639798-269d-419d-ec67-41eb25c0cf52"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 58.3 s, sys: 428 ms, total: 58.7 s\n",
            "Wall time: 1min 1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Evaluación mejor estimador train"
      ],
      "metadata": {
        "id": "j6uGNwHATVue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_stem.best_estimator_.steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8mDcJi2UE__",
        "outputId": "9cc900d5-2f6a-41ab-9034-f67293b5b0a9"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('custom_proccesing', CustomTransformer()),\n",
              " ('clf', SVC(C=1, kernel='linear'))]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que el mejor model es el random forest"
      ],
      "metadata": {
        "id": "XWzFOS2fUGOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  precision = precision_score(y_true, y_pred)\n",
        "  recall = recall_score(y_true, y_pred)\n",
        "  f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "  print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "  print(\"Precision: {:.2f}%\".format(precision * 100))\n",
        "  print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "  print(\"F1-score: {:.2f}%\".format(f1 * 100))\n",
        "\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "Y8-YG_FPT_Bo"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = grid_search_stem.best_estimator_.predict(X_train)"
      ],
      "metadata": {
        "id": "eODnlFGTT7vz"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(y_train, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gizcQ2U1TemD",
        "outputId": "efda62bb-810b-4f4e-b076-0b978f3c5819"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.00%\n",
            "Precision: 50.00%\n",
            "Recall: 100.00%\n",
            "F1-score: 66.67%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        16\n",
            "           1       0.50      1.00      0.67        16\n",
            "\n",
            "    accuracy                           0.50        32\n",
            "   macro avg       0.25      0.50      0.33        32\n",
            "weighted avg       0.25      0.50      0.33        32\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Gridsearch with lemmatization"
      ],
      "metadata": {
        "id": "oZZRO2g3W2C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for grid search for each model\n",
        "parameters = [\n",
        "    {\n",
        "        'clf': [SVC()],\n",
        "        'clf__kernel': ['linear', 'rbf'],\n",
        "        'clf__C': [1, 10, 100],\n",
        "    },\n",
        "    {\n",
        "        'clf': [RandomForestClassifier()],\n",
        "        'clf__n_estimators': [50, 100, 200,100, 1000],\n",
        "        'clf__max_depth': [None, 10, 20],\n",
        "    },\n",
        "    {\n",
        "        'clf': [LogisticRegression()],\n",
        "        'clf__C': [0.1, 1, 10],\n",
        "        'clf__penalty': ['l1', 'l2'],\n",
        "    },\n",
        "    {\n",
        "        'clf': [MultinomialNB()],\n",
        "        'clf__alpha': [0.01, 0.1, 1.0],\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "87tks-slTepC"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search with scoring parameter\n",
        "grid_search_lemm = GridSearchCV(pipe_preparacion_lemm, parameters, scoring='accuracy', verbose=0)"
      ],
      "metadata": {
        "id": "z5FUPGYjTer2"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    # Fit the grid search\n",
        "    grid_search_lemm.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iliP1ADrW-rf",
        "outputId": "33eb0757-4802-4816-af91-2cbe2852d5c8"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 47 s, sys: 1.96 s, total: 49 s\n",
            "Wall time: 48.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Evaluación mejor estimador train"
      ],
      "metadata": {
        "id": "WBBOYUA3Ydov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_stem.best_estimator_.steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVbzH7-vW-uI",
        "outputId": "9c8b0859-dd11-482c-96ae-de7cc6f8ab11"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('custom_proccesing', CustomTransformer()),\n",
              " ('clf', SVC(C=1, kernel='linear'))]"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = grid_search_lemm.best_estimator_.predict(X_train)"
      ],
      "metadata": {
        "id": "wNwRhChnYSQ4"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(y_train, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhW-ZxskYMUN",
        "outputId": "a4050c57-d0ec-4ea5-d8bb-32c06a4da41e"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n",
            "Precision: 100.00%\n",
            "Recall: 100.00%\n",
            "F1-score: 100.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       1.00      1.00      1.00        16\n",
            "\n",
            "    accuracy                           1.00        32\n",
            "   macro avg       1.00      1.00      1.00        32\n",
            "weighted avg       1.00      1.00      1.00        32\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusión Entrenamiento\n",
        "\n",
        "La opción de lemmatization funcionó mucho mejor para la clasificación en el caso de estudio que la opción de stemming. Obteniendo un resultado perfecto en métricas para dataset train y test."
      ],
      "metadata": {
        "id": "LUcuC63TYZH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Evalución de Modelo"
      ],
      "metadata": {
        "id": "FoVEQADrn8D7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación con el dataset test del mejor modelo"
      ],
      "metadata": {
        "id": "JvRySdlAY3n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "    def quitar_tildes(self,texto):\n",
        "      # Normalizar el texto en forma NFD (Normalization Form D)\n",
        "      texto_normalizado = unicodedata.normalize('NFD', texto)\n",
        "      # Filtrar los caracteres que no son marcas diacríticas\n",
        "      texto_sin_tildes = ''.join(c for c in texto_normalizado if unicodedata.category(c) != 'Mn')\n",
        "      # Devolver el texto sin tildes\n",
        "      return texto_sin_tildes\n",
        "\n",
        "    def manage_stop_words(self,tonekized_text):\n",
        "      stop_words = set(stopwords.words(\"spanish\"))\n",
        "      words = [word for word in tonekized_text if word not in stop_words]\n",
        "      return words\n",
        "\n",
        "    def lemmatization(self,tonekized_text):\n",
        "      lemmatizer = WordNetLemmatizer()\n",
        "      words = [lemmatizer.lemmatize(word) for word in tonekized_text]\n",
        "      return words\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "      X_copy = X.copy()\n",
        "\n",
        "      # Data Cleaning\n",
        "      X_copy['text'] = X_copy['text'].str.lower()\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : self.quitar_tildes(x))\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : re.sub(r'[^a-z\\s]', '', x))\n",
        "      #Tokenization\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : word_tokenize(x))\n",
        "      #stop words\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : self.manage_stop_words(x))\n",
        "      #lemmatization\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : self.lemmatization(x))\n",
        "\n",
        "      X_copy['text'] = X_copy['text'].apply(lambda x : \" \".join(x))\n",
        "\n",
        "      vectorizer = CountVectorizer()\n",
        "      X = vectorizer.fit_transform(X_copy['text'])\n",
        "      vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "      return vectorized_df\n",
        "\n",
        "pipe_preparacion_lemm = Pipeline(steps=[\n",
        "    ('custom_proccesing', CustomTransformer()),\n",
        "])"
      ],
      "metadata": {
        "id": "R5cPho4MaQhH"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_trans = pipe_preparacion_lemm.fit_transform(X_train)\n",
        "X_test_trans = pipe_preparacion_lemm.transform(X_test)\n",
        "list_of_columns_train = list(X_train_trans.columns)\n",
        "list_of_columns_test = list(X_test_trans.columns)\n",
        "intersection_list = list(set(list_of_columns_train).intersection(set(list_of_columns_test)))\n",
        "X_test_trans = X_test_trans[intersection_list]\n",
        "\n",
        "#for c in list_of_columns_train:\n",
        "#  if c not in list_of_columns_test:\n",
        "#    X_test_trans[c] = 0\n",
        "# Create a DataFrame with the missing columns set to 0\n",
        "missing_columns = list(set(list_of_columns_train) - set(list_of_columns_test))\n",
        "missing_df = pd.DataFrame(0, index=X_test_trans.index, columns=missing_columns)\n",
        "\n",
        "# Concatenate the missing columns to X_test_trans\n",
        "X_test_trans = pd.concat([X_test_trans, missing_df], axis=1)\n",
        "X_test_trans = X_test_trans[list_of_columns_train]"
      ],
      "metadata": {
        "id": "zA403JfAaryH"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = SVC(C=1, kernel='linear')#RandomForestClassifier(max_depth=10, n_estimators=50)\n",
        "best_model.fit(X_train_trans, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "gHXe02R7d4xS",
        "outputId": "5eb02d0e-3d4d-415f-b2ec-d85df33ec49a"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(X_test_trans)\n",
        "evaluate_model(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtYkL8Z6ZS4T",
        "outputId": "3fe9680d-b2b1-4e5e-99b2-153697dfb7f8"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n",
            "Precision: 100.00%\n",
            "Recall: 100.00%\n",
            "F1-score: 100.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rendimiento perfecto con el dataset de test**"
      ],
      "metadata": {
        "id": "XDTt0Axsfhzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Creación de scripts solicitados"
      ],
      "metadata": {
        "id": "1J9gxSL_ferV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 export model files"
      ],
      "metadata": {
        "id": "Qc3z4Z0wq1VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model_words.txt', 'w') as file:\n",
        "  file.writelines(s + '\\n' for s in list_of_columns_train)"
      ],
      "metadata": {
        "id": "XIphnWExj1sQ"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_words = []\n",
        "with open('model_words.txt', 'r') as file:\n",
        "  list_of_words = file.read().split()"
      ],
      "metadata": {
        "id": "Jf3xqt32j1vt"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(best_model, 'classify.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q58_nEDNpOBz",
        "outputId": "e5c3afba-686d-49e1-b0db-c5b6ace30d06"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['classify.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(pipe_preparacion_lemm, 'prepare.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6I49xP4pOEs",
        "outputId": "2a4e0526-2a72-41a5-c507-f6c379076cc6"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['prepare.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Intentar con nuevos chats"
      ],
      "metadata": {
        "id": "PfsiZIMhq6sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match_columns(pipe, data):\n",
        "  trans_data = pipe.transform(data)\n",
        "  model_words = []\n",
        "  with open('model_words.txt', 'r') as file:\n",
        "    model_words = file.read().split()\n",
        "\n",
        "  list_of_columns_test = list(trans_data.columns)\n",
        "  intersection_list = list(set(model_words).intersection(set(list_of_columns_test)))\n",
        "  X_test_trans = trans_data[intersection_list]\n",
        "\n",
        "  missing_columns = list(set(model_words) - set(list_of_columns_test))\n",
        "  missing_df = pd.DataFrame(0, index=X_test_trans.index, columns=missing_columns)\n",
        "  X_test_trans = pd.concat([X_test_trans, missing_df], axis=1)\n",
        "  X_test_trans = X_test_trans[model_words]\n",
        "\n",
        "  return X_test_trans"
      ],
      "metadata": {
        "id": "ZiACjFCmuIEa"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1=\"\"\"\n",
        "Agente (Laura): ¡Hola! ¿En qué puedo ayudarte hoy?\n",
        "\n",
        "Cliente (Carlos): Hola, estoy buscando un nuevo smartphone. Mi viejo ya está fallando y necesito uno con una buena cámara y batería duradera.\n",
        "\n",
        "Agente (Laura): Entiendo, Carlos. Tenemos una amplia gama de smartphones. ¿Tienes alguna marca en mente o alguna característica específica que estés buscando además de una buena cámara y batería?\n",
        "\n",
        "Cliente (Carlos): He escuchado cosas buenas sobre los modelos de Samsung. También quiero que tenga suficiente espacio de almacenamiento porque tomo muchas fotos y videos.\n",
        "\n",
        "Agente (Laura): Perfecto, Samsung es una excelente elección. Te recomendaría el Samsung Galaxy S21. Tiene una cámara de 64MP, batería de 4000mAh y viene con 128GB de almacenamiento interno. ¿Qué te parece?\n",
        "\n",
        "Cliente (Carlos): Suena bien. ¿Cuánto cuesta?\n",
        "\n",
        "Agente (Laura): Actualmente, el Samsung Galaxy S21 está en oferta por $799. Además, ofrecemos financiación sin intereses si lo prefieres.\n",
        "\n",
        "Cliente (Carlos): Eso suena genial. ¿Qué otros beneficios ofrece este modelo?\n",
        "\n",
        "Agente (Laura): Además de la impresionante cámara y batería, el Galaxy S21 cuenta con un procesador muy rápido, pantalla de 6.2 pulgadas con resolución Full HD+ y es resistente al agua y al polvo. También incluye la posibilidad de expandir el almacenamiento con una tarjeta microSD.\n",
        "\n",
        "Cliente (Carlos): Parece que es justo lo que estoy buscando. ¿Cómo funciona el proceso de financiación?\n",
        "\n",
        "Agente (Laura): Es muy sencillo. Puedes elegir pagar en cuotas mensuales sin intereses durante 12 meses. Solo necesitas una tarjeta de crédito válida y completar una breve solicitud en línea.\n",
        "\n",
        "Cliente (Carlos): Perfecto, me interesa la financiación. ¿Cómo podemos proceder?\n",
        "\n",
        "Agente (Laura): ¡Excelente! Te enviaré un enlace para que completes la solicitud en línea. Una vez aprobada, te enviaremos el smartphone a tu domicilio sin costo adicional en un plazo de 3 a 5 días hábiles. ¿Te parece bien?\n",
        "\n",
        "Cliente (Carlos): Sí, eso suena perfecto. Gracias por tu ayuda, Laura.\n",
        "\n",
        "Agente (Laura): Es un placer, Carlos. Te enviaré el enlace de inmediato. ¿Puedes confirmar que recibiste el enlace y que todo está en orden?\n",
        "\n",
        "Cliente (Carlos): Sí, acabo de recibirlo. Déjame completar la solicitud.\n",
        "\n",
        "(Pausa mientras Carlos completa la solicitud)\n",
        "\n",
        "Cliente (Carlos): Listo, ya envié la solicitud.\n",
        "\n",
        "Agente (Laura): Perfecto, Carlos. Déjame verificar... Sí, tu solicitud ha sido aprobada. Hemos procesado tu pedido y el Samsung Galaxy S21 será enviado a tu dirección. Deberías recibirlo en 3 a 5 días hábiles.\n",
        "\n",
        "Cliente (Carlos): ¡Genial! Muchas gracias, Laura. Estoy muy emocionado por recibir mi nuevo smartphone.\n",
        "\n",
        "Agente (Laura): Me alegra escuchar eso, Carlos. Si necesitas algo más o tienes alguna pregunta, no dudes en contactarnos. ¡Que disfrutes tu nuevo teléfono!\n",
        "\n",
        "Cliente (Carlos): Seguro, gracias de nuevo. ¡Hasta luego!\n",
        "\n",
        "Agente (Laura): ¡Hasta luego, Carlos! Que tengas un excelente día.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7GwYflaRmsLt"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = pd.DataFrame({\"text\":[chat1]})\n",
        "pipe = joblib.load('prepare.pkl')\n",
        "data = match_columns(pipe, data)"
      ],
      "metadata": {
        "id": "R9iRoj-ksLE2"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = joblib.load('classify.pkl')\n",
        "model.predict(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4DcEVJeuUhi",
        "outputId": "64cef76c-a251-4cd4-b5ea-6afca5b6b435"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep scikit-learn"
      ],
      "metadata": {
        "id": "xVKPUvlqueOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6425b401-264c-4854-dc58-53da404cfa24"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn==1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNjelh_rFyjN"
      },
      "execution_count": 198,
      "outputs": []
    }
  ]
}